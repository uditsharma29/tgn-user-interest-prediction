# Temporal Heterogeneous Graph Model for User Interest Prediction

This project implements a temporal graph neural network (GNN) model to predict the top 5 item IDs a user (represented by IP address) might be interested in during the next week. It uses PyTorch and PyTorch Geometric.

## Project Goal

The primary goal is to model user-item interactions over time (weekly snapshots) and predict future interests. The model learns from historical sequences of weekly interaction graphs to forecast which items a user will likely interact with.

## File Structure

```
.
├── generate_dataset_csv.py  # Generates a dummy CSV dataset of user-item interactions.
├── data_utils.py            # Utilities for loading and processing data into PyG HeteroData snapshots.
├── model.py                 # Defines the GNN encoder, Transformer, and the main UserInteractionPredictor model.
├── train.py                 # Main script for training the model and evaluating Top-K predictions.
├── requirements.txt         # Python package dependencies.
└── user_item_interactions.csv # (Generated by generate_dataset_csv.py) The input dataset.
```

## Setup and Installation

1.  **Create a Python virtual environment** (recommended):
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```

2.  **Install dependencies**:
    Make sure you have `pip` installed. The project relies on PyTorch and PyTorch Geometric.
    It's crucial to install versions of PyTorch that are compatible with your PyTorch Geometric version and your system (CPU/CUDA).

    Refer to the [PyTorch installation guide](https://pytorch.org/get-started/locally/) to find the correct command for your system (select your OS, package manager (pip), language (Python), and compute platform (CPU or specific CUDA version)).

    Once PyTorch is installed according to the official guidelines, install the other packages:
    ```bash
    pip install -r requirements.txt
    ```
    The `requirements.txt` currently lists:
    ```
    torch
    torch_geometric
    pandas
    numpy
    ```
    Ensure your PyTorch installation (done prior to `pip install -r requirements.txt`) matches the version expected by the PyTorch Geometric version that gets installed. If you encounter `torch.fx` related errors, it's often due to PyTorch/PyTorch Geometric version incompatibility.

## Running the Project

1.  **Generate the Dataset**:
    First, run the script to generate the dummy interaction data:
    ```bash
    python generate_dataset_csv.py
    ```
    This will create `user_item_interactions.csv`.

2.  **Train the Model**:
    Once the dataset is generated, run the training script:
    ```bash
    python train.py
    ```
    This script will:
    *   Load the CSV data.
    *   Create weekly `HeteroData` graph snapshots.
    *   Initialize the `UserInteractionPredictor` model.
    *   Train the model using an MSE loss on observed interaction counts for weeks 1-8.
    *   Evaluate the model every 5 epochs by predicting Top-K items for users in week 9 and calculating Precision@K and Recall@K.
    *   Print details of the data being fed into the model for the first training step of each epoch.

## Core Components

### 1. Data Generation (`generate_dataset_csv.py`)
*   Creates a CSV file (`user_item_interactions.csv`) with columns: `ip_address`, `item_id`, `n_interactions` (interaction count), and `week_number`.
*   `n_interactions` (number of interactions) is generated with a bias towards smaller numbers using a Zipf distribution.
*   Simulates data over a configurable number of weeks.

### 2. Data Processing (`data_utils.py`)
*   `load_interactions_from_csv()`: Reads the generated CSV, maps IP addresses and item IDs to unique integer IDs.
*   `create_weekly_heterodata_from_df()`: Converts the interaction data for a single week into a `torch_geometric.data.HeteroData` object.
    *   Nodes: `'user'` (from IP addresses) and `'item'` (from item IDs).
    *   Edges: `('user', 'interacts_with', 'item')` representing user-item interactions.
    *   Edge Label: The `n_interactions` (interaction count) is stored as `edge_label`.
    *   Node Features: Initially, random static features are generated for all users and items (`USER_FEAT_DIM_DEFAULT` and `ITEM_FEAT_DIM_DEFAULT`). These are assigned to `snapshot['user'].x` and `snapshot['item'].x`.

### 3. Model Architecture (`model.py`)

*   **`GNNEncoder(nn.Module)`**:
    *   A simple SAGEConv layer.
    *   Designed to be wrapped by `to_hetero` from PyTorch Geometric.
    *   Its `forward` method *only* performs the GNN convolution, returning raw node embeddings.
    *   ReLU, Dropout, and BatchNorm are applied *after* this raw output in the main model, per node type.

*   **`PositionalEncoding(nn.Module)`**:
    *   Standard Transformer positional encoding.

*   **`UserInteractionPredictor(nn.Module)`**: The main temporal model.
    *   **Initialization (`__init__`)**:
        *   Takes dataset metadata, feature dimensions, and various hyperparameters.
        *   Initializes the `GNNEncoder` and wraps it with `to_hetero` to handle the heterogeneous `'user'` and `'item'` nodes.
        *   Sets up separate ReLU, Dropout, and BatchNorm1d layers for `'user'` and `'item'` node features to be applied after the GNN.
        *   Includes a projection layer (`self.user_initial_proj`) for user features if their initial dimension doesn't match `gnn_hidden_channels`. This is used because user nodes only act as source nodes and their features are not updated by the SAGEConv layer.
        *   Initializes a standard `nn.Transformer` for temporal processing.
        *   Initializes an MLP (`self.user_to_item_scores_mlp`) to predict scores for all items for a given user embedding.
    *   **Forward Pass (`forward`)**:
        *   Takes a list of historical graph snapshots and a target snapshot.
        *   Processes each historical snapshot:
            1.  Obtains raw embeddings using `self.gnn_encoder(x_dict, edge_index_dict)`.
            2.  For `'user'` features: If the GNN output is `None` (because users are not destination nodes), it uses the initial features from `x_dict['user']` and projects them via `self.user_initial_proj`. Otherwise, it uses the GNN output.
            3.  Applies the dedicated ReLU, Dropout, and BatchNorm layers to the user features.
            4.  For `'item'` features: Retrieves them from the GNN output (assuming they are always present as items are destination nodes) and applies the dedicated ReLU, Dropout, and BatchNorm layers.
            5.  Collects these processed user and item embeddings for each snapshot in the historical window.
        *   Stacks the sequences of user and item embeddings.
        *   Applies positional encoding to the user embedding sequence.
        *   Feeds the user sequence (as source) and the last user embedding (as target for decoder-like behavior) into the `nn.Transformer` to get temporal user embeddings.
        *   **Training Mode (MSE Loss)**: For compatibility with the training script's MSE loss, it computes dot products between the temporal user embeddings and the item embeddings from the *last historical snapshot* for the *observed edges* in the `target_snapshot`. This is a simplification to train the GNN and Transformer components.
    *   **Prediction (`predict_top_k_for_user`)**:
        *   Takes a single user's temporal embedding and the item embeddings from the relevant time step.
        *   Uses `self.user_to_item_scores_mlp` to compute scores for all possible items for that user.
        *   Returns the raw scores, and the top-K item indices and their scores.

### 4. Training and Evaluation (`train.py`)
*   **Constants**: Defines paths, model hyperparameters, and training settings.
*   **Data Loading**: Loads data using `load_interactions_from_csv` and creates all weekly `HeteroData` snapshots using `create_weekly_heterodata_from_df`. Static random features are generated once for all users and items.
*   **Model Initialization**: Instantiates `UserInteractionPredictor`.
*   **Training Loop**:
    *   Iterates for a fixed number of `EPOCHS`.
    *   For each epoch, iterates through the dataset creating historical windows and target snapshots.
    *   The model's `forward` pass is called to get predicted interaction scores for observed edges in the target snapshot.
    *   An `nn.MSELoss` is computed between these predicted scores and the true `n_interactions` (interaction counts) from the target snapshot's `edge_label`.
    *   Optimizer updates the model parameters.
*   **Evaluation Loop (Top-K)**:
    *   Performed every 5 epochs, using week 9 as the validation set.
    *   It re-extracts embeddings for the historical window leading up to week 9:
        *   Critically, it replicates the GNN output processing logic from `UserInteractionPredictor.forward()`:
            *   Calls `model.gnn_encoder`.
            *   Handles `None` for user features by using initial features and `model.user_initial_proj`.
            *   Applies `model.user_relu/dropout/bn` and `model.item_relu/dropout/bn` to the respective features.
        *   These processed embeddings are then fed through `model.pos_encoder` and `model.transformer` to get final temporal user embeddings for week 9.
        *   Item embeddings from the last snapshot of the validation history are used.
    *   For users present in the week 9 ground truth, it calls `model.predict_top_k_for_user()`.
    *   Calculates and prints average Precision@K and Recall@K.

## Assumptions and Simplifications
*   **Dummy Dataset**: The project currently uses randomly generated data.
*   **Static Node Features**: User and item node features are random and static (do not change over time). In a real-world scenario, these could be learned or derived from user/item attributes.
*   **GNN for 'item' nodes only**: Due to the directed nature `user -> item`, the SAGEConv layer in the GNN primarily updates 'item' node representations. User node representations are passed through their initial features (possibly projected) and then processed.
*   **Training Target**: The model is trained using MSE loss on the *count* of interactions for observed edges. The final goal is Top-K prediction, which uses a different output head (`user_to_item_scores_mlp`). This means the MSE training is a proxy task to learn useful GNN and Transformer representations.
*   **Transformer Target**: The Transformer uses the user embeddings from the last historical step as the "target" for its decoder-like input, aiming to predict the next state of user embeddings.