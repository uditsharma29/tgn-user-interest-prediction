import pandas as pd
import numpy as np
import random

# --- Dataset Parameters ---
NUM_UNIQUE_IPS = 1000
NUM_UNIQUE_ITEMS = 500
NUM_INTERACTION_RECORDS = 100000
MAX_N_INTERACTIONS = 100
ZIPF_PARAM_N_INTERACTIONS = 2.0
NUM_WEEKS = 9
OUTPUT_CSV_PATH = "user_item_interactions.csv"

def generate_random_ip():
    """Generates a random IP address string."""
    return f"{random.randint(1, 255)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"

def generate_random_item_id(prefix=""):
    """Generates a random item ID string."""
    return f"{prefix}{random.randint(10000, 99999)}"

def main():
    print(f"Generating dataset with {NUM_INTERACTION_RECORDS} records...")

    # Generate pools of unique IPs and Item IDs
    ip_pool = [generate_random_ip() for _ in range(NUM_UNIQUE_IPS)]
    item_id_pool = [generate_random_item_id() for _ in range(NUM_UNIQUE_ITEMS)]

    data = []

    for i in range(NUM_INTERACTION_RECORDS):
        if (i+1) % 5000 == 0:
            print(f"Generated {i+1}/{NUM_INTERACTION_RECORDS} records...")

        ip = random.choice(ip_pool)
        item_id_val = random.choice(item_id_pool)
        
        # Generate n_interactions with Zipf distribution for bias towards smaller numbers
        n = min(np.random.zipf(ZIPF_PARAM_N_INTERACTIONS), MAX_N_INTERACTIONS)
        n = max(1, int(n)) # Ensure it's at least 1
        
        week = np.random.randint(1, NUM_WEEKS + 1)

        data.append({
            "ip_address": ip,
            "item_id": item_id_val,
            "n_interactions": n,
            "week_number": week
        })

    df = pd.DataFrame(data)

    # Ensure no duplicate rows for the exact same (ip, item, week) combination,
    # as n_interactions should represent the total for that pairing in that week.
    # If duplicates are generated by chance, sum their n_interactions.
    df = df.groupby(["ip_address", "item_id", "week_number"])["n_interactions"].sum().reset_index()
    
    # Shuffle the dataset (optional, but good practice)
    df = df.sample(frac=1).reset_index(drop=True)

    df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"\nDataset saved to {OUTPUT_CSV_PATH}")
    print(f"Total unique IPs in generated CSV: {df['ip_address'].nunique()}")
    print(f"Total unique Item IDs in generated CSV: {df['item_id'].nunique()}")
    print(f"Total records after potential aggregation: {len(df)}")
    print("Dataset head:")
    print(df.head())

if __name__ == "__main__":
    main() 